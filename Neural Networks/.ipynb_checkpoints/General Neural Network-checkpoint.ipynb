{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of a General Neural Network\n",
    "\n",
    "This will server as implementation of a neural network with one hidden layer which consits of 2 units. We will be implementing the XOR function using this neural network.\n",
    "\n",
    "We will first perform forward propagation and then the backward propagation to achieve the optimal values for weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 2), (4, 1))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "Y = np.array([[0,1,1,0]]).T\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig(z):\n",
    "    return 1/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivativeSig(z):\n",
    "    return sig(z)*(1 - sig(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n"
     ]
    }
   ],
   "source": [
    "# One hidden layer with weights\n",
    "wh = 2 * np.random.random((2, 2)) - 1\n",
    "bh = 2 * np.random.random((1, 2)) - 1\n",
    "wo = 2 * np.random.random((2, 1)) - 1\n",
    "bo = 2 * np.random.random((1, 1)) - 1\n",
    "lr = 0.1\n",
    "print(wh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.03344746],\n",
       "        [0.97153982],\n",
       "        [0.96992217],\n",
       "        [0.03085937]]), array([[-5.92458833,  5.01730344],\n",
       "        [ 6.29021111, -5.44287542]]), array([[-3.70752326, -2.74735046]]), array([[8.16135015],\n",
       "        [8.31100732]]), array([[-4.0598541]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Forward propagation with one hidden layer\n",
    "for iter in range(10000):\n",
    "    output0 = X\n",
    "    inputHidden = np.dot(output0, wh) + bh\n",
    "    outputHidden = sig(inputHidden)\n",
    "    inputForOutputLayer = np.dot(outputHidden, wo) + bo\n",
    "    output = sig(inputForOutputLayer)\n",
    "\n",
    "    # The first two terms for the back propagation of output layer\n",
    "    first_term_output_layer = output - Y # Yp - Ya\n",
    "    second_term_output_layer = derivativeSig(inputForOutputLayer)\n",
    "    first_two_output_layer = first_term_output_layer * second_term_output_layer\n",
    "\n",
    "    # To get the first term for hidden layer\n",
    "    # We back propagate the first two terms of the output layer/next layer and\n",
    "    # Multiply those two terms with the weights\n",
    "    first_term_hidden_layer = np.dot(first_two_output_layer, wo.T)\n",
    "    second_term_hidden_layer = derivativeSig(inputHidden)\n",
    "    first_two_hidden_layer = first_term_hidden_layer * second_term_hidden_layer\n",
    "\n",
    "    changes_output = np.dot(outputHidden.T, first_two_output_layer)\n",
    "    changes_output_bias = np.sum(first_two_output_layer, axis=0, keepdims=True)\n",
    "    \n",
    "    changes_hidden = np.dot(output0.T, first_two_hidden_layer)\n",
    "    changes_hidden_bias = np.sum(first_two_hidden_layer, axis=0, keepdims=True)\n",
    "\n",
    "    wo = wo - (lr * changes_output)\n",
    "    bo = bo - (lr * changes_output_bias)\n",
    "    \n",
    "    wh = wh - (lr * changes_hidden)\n",
    "    bh = bh - (lr * changes_hidden_bias)\n",
    "\n",
    "output0 = X\n",
    "inputHidden = np.dot(output0, wh) + bh\n",
    "outputHidden = sig(inputHidden)\n",
    "inputForOutputLayer = np.dot(outputHidden, wo) + bo\n",
    "output = sig(inputForOutputLayer)\n",
    "\n",
    "output, wh, bh, wo, bo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
